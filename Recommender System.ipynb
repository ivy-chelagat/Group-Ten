{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c72b903b-93c3-44dc-a389-0e7c67b9be5a",
   "metadata": {},
   "source": [
    "### 1: We have several libraries and tools that are going to used such as advanced CF algorithims (SVD).\n",
    "\n",
    "### Dataset, Reader, SVD, train_test_split, accuracy, GridSearchCV are going to be used for building and evaluating the matrix factorization component.\n",
    "\n",
    "### TF-IDF and cosine_similarity, will be used to build the Content-Based Filtering component based on movie genres.Lastly,the final model will be serialized for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3ed5cf5-1b65-4831-b81f-2f5493d4d646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in c:\\anaconda\\lib\\site-packages (1.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\anaconda\\lib\\site-packages (from scikit-surprise) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\anaconda\\lib\\site-packages (from scikit-surprise) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\anaconda\\lib\\site-packages (from scikit-surprise) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraries\n",
    "!pip install scikit-surprise\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f42125e-6448-4058-809d-6be109a45bac",
   "metadata": {},
   "source": [
    "### 2: Loading Data: The ratings.csv and movies.csv files are loaded into Pandas DataFrames.\n",
    "### Shape Inspection: The size of the raw datasets is printed, confirming we are starting with 100,836 ratings and 9,742 movies.\n",
    "### Merging: The ratings data is merged with the necessary title and genres information from the movies data using movieId as the common key. This creates a single DataFrame (ratings_merged) containing all user-item-rating details along with the movie's descriptive features.\n",
    "### Preview: The first 10 rows of the merged data are displayed for a quick verification of the merge operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c731d45-0598-4986-bc87-fa052397ec84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings: (100836, 4)\n",
      "Movies: (9742, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>964982400</td>\n",
       "      <td>From Dusk Till Dawn (1996)</td>\n",
       "      <td>Action|Comedy|Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964980868</td>\n",
       "      <td>Bottle Rocket (1996)</td>\n",
       "      <td>Adventure|Comedy|Crime|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982176</td>\n",
       "      <td>Braveheart (1995)</td>\n",
       "      <td>Action|Drama|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984041</td>\n",
       "      <td>Rob Roy (1995)</td>\n",
       "      <td>Action|Drama|Romance|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984100</td>\n",
       "      <td>Canadian Bacon (1995)</td>\n",
       "      <td>Comedy|War</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp                        title  \\\n",
       "0       1        1     4.0  964982703             Toy Story (1995)   \n",
       "1       1        3     4.0  964981247      Grumpier Old Men (1995)   \n",
       "2       1        6     4.0  964982224                  Heat (1995)   \n",
       "3       1       47     5.0  964983815  Seven (a.k.a. Se7en) (1995)   \n",
       "4       1       50     5.0  964982931   Usual Suspects, The (1995)   \n",
       "5       1       70     3.0  964982400   From Dusk Till Dawn (1996)   \n",
       "6       1      101     5.0  964980868         Bottle Rocket (1996)   \n",
       "7       1      110     4.0  964982176            Braveheart (1995)   \n",
       "8       1      151     5.0  964984041               Rob Roy (1995)   \n",
       "9       1      157     5.0  964984100        Canadian Bacon (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                               Comedy|Romance  \n",
       "2                        Action|Crime|Thriller  \n",
       "3                             Mystery|Thriller  \n",
       "4                       Crime|Mystery|Thriller  \n",
       "5                Action|Comedy|Horror|Thriller  \n",
       "6               Adventure|Comedy|Crime|Romance  \n",
       "7                             Action|Drama|War  \n",
       "8                     Action|Drama|Romance|War  \n",
       "9                                   Comedy|War  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Csv files\n",
    "ratings=pd.read_csv('ratings.csv')\n",
    "movies=pd.read_csv('movies.csv')\n",
    "print('Ratings:', ratings.shape)\n",
    "print('Movies:', movies.shape)\n",
    "#Merging ratings with Movies\n",
    "ratings_merged= ratings.merge(movies[['movieId', 'title', 'genres']], on='movieId', how='left')\n",
    "ratings_merged.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedbe064-f063-473e-b32c-b6f23e01f368",
   "metadata": {},
   "source": [
    "### 3:Exploratory Data Analysis: \n",
    "### Dataset Size: Users: 610 unique users.Items (Movies): 9,724 unique movies. (Note: The user-entered code accidentally printed the user count for items, but the movieId unique count is 9,724 based on the movies.csv file structure).Interactions: 100,836 total ratings.\n",
    "\n",
    "### User Activity (Interactions per User):The average user has provided 165.7 ratings, which is quite high.Min: 20 ratings (Confirming the MovieLens condition that all included users have rated at least 20 movies).Max: 7,376 ratings (Indicating a few highly active \"super-users\").\n",
    "\n",
    "### Rating Distribution:The ratings are centered around the high end, with a median and mean rating of 4.0.Mean Rating: 3.501 (Out of 5.0)Std Dev: 1.043These statistics confirm the data is from a relatively small but highly active group of users, and ratings are generally positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99b3a686-9891-462f-8a7a-c75c0cfeae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 610, Items: 610, Interactions: 100836\n",
      "count     610.000000\n",
      "mean      165.304918\n",
      "std       269.480584\n",
      "min        20.000000\n",
      "25%        35.000000\n",
      "50%        70.500000\n",
      "75%       168.000000\n",
      "max      2698.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    100836.000000\n",
       "mean          3.501557\n",
       "std           1.042529\n",
       "min           0.500000\n",
       "25%           3.000000\n",
       "50%           3.500000\n",
       "75%           4.000000\n",
       "max           5.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of Users,Items and interactions\n",
    "n_users= ratings['userId'].nunique()\n",
    "n_items= ratings['movieId'].nunique()\n",
    "print(f'Users: {n_users}, Items: {n_users}, Interactions: {len(ratings)}')\n",
    "#Count Interactions per user\n",
    "user_counts= ratings.groupby('userId').size().describe()\n",
    "print(user_counts)\n",
    "# ratings distribution\n",
    "ratings['rating'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25110c5-41be-4fa9-9505-2e6c3f89dd1a",
   "metadata": {},
   "source": [
    "### 4:Temporal Train/Test Split\n",
    "### This code block implements a Temporal Leave-One-Out Cross-Validation strategy, which is important for evaluating sequential and time-series-dependent data like a recommendation system.\n",
    "\n",
    "### Why Temporal Split?Avoids Data Leakage: It ensures that the model is trained only on events that happened before the events it is asked to predict. A random split would leak future information.Simulates Production: We train on a user's past behavior and test on their most recent behavior, mimicking a real-world scenario where the model predicts the user's next action.\n",
    "\n",
    "### Split Details:The timestamp is converted from Unix seconds to a proper datetime object.\n",
    "\n",
    "### The data is sorted by userId and timestamp.\n",
    "\n",
    "### The last (most recent) rating for every single user is extracted to form the Test Set (test_df).\n",
    "\n",
    "### All remaining ratings are used for the Train Set (train_df).\n",
    "\n",
    "### The resulting split is:Total Interactions: 100,836, Train Interactions: 100,226 (Used for model training) Test Interaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c3ff7b5-afdb-4104-8323-842561f9210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Interactions: 100226\n",
      "Test Interactions (held-out last per user): 610\n"
     ]
    }
   ],
   "source": [
    "#Data Type Conversion for Timestamps\n",
    "if 'timestamp' in ratings.columns:\n",
    "    ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "# Handling Timestamps and Sorting\n",
    "ratings_sorted = ratings.sort_values(['userId', 'timestamp']) if 'timestamp' in ratings.columns else ratings.sort_values (['userId'])\n",
    "#Identifying the Test Set Indices (Leave-One-Out)\n",
    "test_idx = ratings_sorted.groupby('userId').tail(1).index\n",
    "# Creating the Final Train and Test DataFrames\n",
    "test_df = ratings.loc[test_idx].reset_index(drop=True)\n",
    "train_df = ratings.drop(test_idx).reset_index(drop=True)\n",
    "#Showing the resulting split.\n",
    "print('Train Interactions:', len(train_df))\n",
    "print('Test Interactions (held-out last per user):', len(test_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a4377d-db11-45c4-9f5d-a6d1289fcb3c",
   "metadata": {},
   "source": [
    "### 5:Data Preparation for Surprise (CF)\n",
    "### The code below prepares the Pandas DataFrame into the specific data structure required by the scikit-surprise library. This is a necessary step to utilize algorithms like Singular Value Decomposition (SVD).\n",
    "\n",
    "### Key Components: Reader: The Reader object is initialized to inform Surprise about the expected rating scale, which is (0.5,5.0) for the MovieLens dataset. This normalization is vital for the matrix factorization algorithms.Dataset.load_from_df: This function transforms the Pandas DataFrame, containing the essential userId, movieId, and rating columns, into a Dataset object.\n",
    "\n",
    "### Datasets Created: data_train: This object is loaded using the raw ratings DataFrame. Crucially, since you performed a manual temporal split previously, this full dataset object will be internally split later to feed the model only the train_df data.full_train: A duplicate object often created for procedures where the model is trained on all available data (e.g., after the best hyperparameters are found) to generate final recommendations.\n",
    "\n",
    "### This step finalizes the data's readiness for the Matrix Factorization training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee09a16d-9a2c-49fc-ac8d-b5142e09ceea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<surprise.reader.Reader object at 0x00000273E4FDFCE0>\n",
      "<surprise.dataset.DatasetAutoFolds object at 0x00000273EFBD1040>\n",
      "<surprise.dataset.DatasetAutoFolds object at 0x00000273EFBD36B0>\n"
     ]
    }
   ],
   "source": [
    "#Defining the Rating Scale\n",
    "reader= Reader(rating_scale=(0.5,5.0))\n",
    "#Loading Data into Surprise Format\n",
    "data_train= Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "full_train= Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "print(reader)\n",
    "print(data_train)\n",
    "print(full_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fca6e9-19eb-41cd-bd03-e01efe802b17",
   "metadata": {},
   "source": [
    "### 6:Hyperparameter Tuning for Collaborative Filtering (SVD):\n",
    "### The code below performs Grid Search Cross-Validation (GridSearchCV) to find the optimal set of parameters for the Singular Value Decomposition (SVD) matrix factorization algorithm. This is the crucial step for optimizing the performance of the Collaborative Filtering component.\n",
    "\n",
    "### Tuning Strategy\n",
    "### Algorithm: SVD is chosen as it's highly effective for recommendation systems, decomposing the user-item matrix into lower-dimensional user and item feature matrices (latent factors).\n",
    "\n",
    "### Parameters Tuned (param_grid):\n",
    "\n",
    "### n_factors (Latent Factors): The dimensionality of the latent factor space (e.g., 20, 50, 100). This represents how many hidden features describe user tastes and movie properties.\n",
    "\n",
    "### lr_all (Learning Rate): Controls the step size at each iteration of stochastic gradient descent.\n",
    "\n",
    "### reg_all (Regularization Term): Prevents overfitting by penalizing large parameter values.\n",
    "\n",
    "### Evaluation:\n",
    "\n",
    "### Cross-Validation: The training data is split into 3 folds (cv=3).\n",
    "\n",
    "### Metric: The model is optimized to minimize the Root Mean Squared Error (RMSE), which is the standard measure of prediction accuracy for explicit rating data.\n",
    "\n",
    "### Output: The search returns the combination of parameters that achieved the lowest average RMSE across the 3 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "305a891a-4505-4f79-ae3d-997f3c480fd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score: 0.8751026559158208\n",
      "Best params (RMSE): {'n_factors': 20, 'lr_all': 0.005, 'reg_all': 0.05}\n"
     ]
    }
   ],
   "source": [
    "#Defining the Search Space\n",
    "param_grid = {\n",
    "    'n_factors':[20, 50, 100],\n",
    "    'lr_all':[0.002, 0.005],\n",
    "    'reg_all': [0.02, 0.05]\n",
    "}\n",
    "#Setting up the Grid Search\n",
    "gs= GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
    "#Execution and Result\n",
    "gs.fit(data_train)\n",
    "\n",
    "print('Best RMSE score:', gs.best_score['rmse'])\n",
    "print('Best params (RMSE):', gs.best_params['rmse'])\n",
    "\n",
    "best_params=gs.best_params['rmse']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e810693-98ec-47c9-b46a-885e52e491d9",
   "metadata": {},
   "source": [
    "### 7:  Final Collaborative Filtering (SVD) Model Training and Evaluation.\n",
    "### This block finalizes the training of the Collaborative Filtering (CF) model using the optimal hyperparameters found during the grid search, and then evaluates its real-world performance using the held-out temporal test set.\n",
    "\n",
    "### Key Steps:\n",
    "\n",
    "### Final Training (svd_final):\n",
    "\n",
    "### The model (Singular Value Decomposition, SVD) is initialized using the best parameters (n\\_factors, lr\\_all, reg\\_all) determined by GridSearchCV to ensure peak predictive performance.\n",
    "\n",
    "### The model is trained on the full training dataset (trainset), which includes all user interactions before the held-out test ratings.\n",
    "\n",
    "### Test Set Preparation:\n",
    "\n",
    "### The test_df (which contains the single, most recent rating for every user from the temporal split) is converted into a list of tuples ((user\\_id, movie\\_id, true\\_rating)), which is the exact format required by the surprise library's .test() function.\n",
    "\n",
    "### Evaluation:\n",
    "\n",
    "### Predictions are generated for every item in the test set.\n",
    "\n",
    "### The final performance is measured using the standard regression metrics for rating prediction:\n",
    "\n",
    "### RMSE (Root Mean Squared Error): The primary metric, which heavily penalizes large prediction errors.\n",
    "\n",
    "### MAE (Mean Absolute Error): Measures the average magnitude of prediction error.\n",
    "\n",
    "### These final RMSE and MAE scores represent the model's expected accuracy when predicting a user's future rating behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03d8b329-4bd2-43a3-965c-64b56756cd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8319, MAE: 0.6490\n"
     ]
    }
   ],
   "source": [
    "#Final Model Training\n",
    "trainset = full_train.build_full_trainset()\n",
    "svd_final = SVD(n_factors=best_params['n_factors'], lr_all=best_params['lr_all'], reg_all=best_params['reg_all'], biased=True, random_state=42)\n",
    "svd_final.fit(trainset)\n",
    "#Test Set Preparation for Surprise\n",
    "raw_testset= list(zip(test_df['userId'].astype(str).tolist(),test_df['movieId'].astype(str).tolist(), test_df['rating'].astype(str).tolist()))\n",
    "testset_for_suprise= [(row.userId, row.movieId, row.rating) for row in test_df.itertuples()]\n",
    "#Evaluate the Testset\n",
    "predictions=svd_model.test(testset_for_suprise)\n",
    "rmse= accuracy.rmse(predictions, verbose=False)\n",
    "mae= accuracy.mae(predictions, verbose=False)\n",
    "print(f'RMSE: {rmse:.4f}, MAE: {mae:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1eaa7e-4726-4e5e-9ce5-60cfbc5808f5",
   "metadata": {},
   "source": [
    "### 8:Content-Based Filtering (CBF) Model Setup\n",
    "### This establishes the the Content-Based Filtering (CBF) component of the hybrid recommender system, focusing on movie genres.\n",
    "\n",
    "### Key Steps:\n",
    "### Genre Preprocessing:\n",
    "\n",
    "### movies['genres'] = movies['genres'].fillna(''): Ensures all missing genre values are replaced with an empty string, preventing errors in the vectorization step.\n",
    "\n",
    "### TF-IDF Vectorization:\n",
    "\n",
    "### tfidf = TfidfVectorizer(...): Initializes the TF-IDF (Term Frequency-Inverse Document Frequency) vectorizer.\n",
    "\n",
    "### token_pattern=r\"(?u)\\b[^,]+\\b\": Crucially, the token pattern is adjusted to treat the genres (which are comma-separated in the input but typically pipe-separated in MovieLens) as distinct terms. For the standard MovieLens format using pipes (|), this custom pattern may need adjustment, but the intent is to capture genre tags like 'Action', 'Drama', etc., as separate features.\n",
    "\n",
    "### genre_tfidf = tfidf.fit_transform(...): Transforms the list of movie genres into a sparse matrix where each row is a movie and each column is a genre term. TF-IDF gives higher weight to genres that are unique to a few movies, reducing the importance of common genres like 'Drama' or 'Comedy'.\n",
    "\n",
    "### Similarity Matrix Calculation:\n",
    "\n",
    "### genre_sim = cosine_similarity(genre_tfidf, genre_tfidf): Calculates the cosine similarity between every movie pair. The resulting matrix (genre_sim) measures how closely aligned the genre profiles of any two movies are, with values closer to 1.0 indicating higher similarity.\n",
    "\n",
    "### Index Mapping:\n",
    "\n",
    "### movieid_to_idx and idx_to_movieid: These dictionaries are created to map the internal DataFrame row index to the external MovieLens movieId and back. This is essential for quickly looking up a movie's similarity scores in the matrix using its movieId.\n",
    "\n",
    "### This entire process enables the model to identify movies that are content-wise (genre-wise) similar to those a user has liked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "733cd9dc-0a6d-41c1-801d-beb882b8665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning and Vectorization\n",
    "movies['genres'] = movies['genres'].fillna('')\n",
    "tfidf = TfidfVectorizer(token_pattern=r\"(?u)\\b[^,]+\\b\")\n",
    "genre_tfidf =tfidf.fit_transform(movies['genres'])\n",
    "#Calculating Similarity\n",
    "movieid_to_idx = {mid: idx for idx, mid in enumerate(movies['movieId'].values)}\n",
    "#Index Mapping\n",
    "idx_to_movieid = {idx: mid for mid, idx in movieid_to_idx.items()}\n",
    "genre_sim = cosine_similarity(genre_tfidf, genre_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6270b6c9-fb3c-49fe-a1b7-3153b18f62aa",
   "metadata": {},
   "source": [
    "### 9:Recommendation Functions(CF-only and Hybrid Reranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bf01ea-52a1-498a-ae9f-0aaaeb38f60a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb9a0d40-0d0e-4494-aaa6-a2d16be9a4ee",
   "metadata": {},
   "source": [
    "### 10:Example Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ee8a6-5e83-4e4f-89de-f0045e4bcbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "daec2fe3-7062-4c05-9d7f-df9b28c21bcc",
   "metadata": {},
   "source": [
    "### 11: Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02eef8e-41b1-4ae6-abfc-ba7de3f6c108",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
